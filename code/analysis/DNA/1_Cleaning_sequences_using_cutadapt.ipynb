{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dda4fef",
   "metadata": {},
   "source": [
    "## 1. Cleaning sequences using cutadapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd881cd",
   "metadata": {},
   "source": [
    "We will utilize the following code run in the terminal to clean the raw 16S rRNA sequences from marine sediments in fastq format (in the data/raw/16S_rRNA_seqs folder). First, you should navigate with cd to the folder that contains the raw sequences. Once you are there, run the following line to make a file with unique IDs for each sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls DO-*R1* | cut -f 1,2 -d \"_\" > unique-sample-IDs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b2e23",
   "metadata": {},
   "source": [
    "The first command finds the files with the initials you want, in this case, \"DO\", and that include R1 (only forward sequences) in the filename. The second command extracts their identifiers by selecting only the first 2 \"columns\" before the first \"_\", and sends the output to the file unique-sample-IDs.txt. If your sequences have a different name formatting, you might need to modify this code to retrieve the correct IDs.\n",
    "\n",
    "Now, we will remove the primer sequences using cutadapt. The sequences were amplified targeting the V4- V5 hypervariable region by PCR using universal primer set 515F (5' -GTGYCAGCMGCCGCGGTAA- 3′) and 926R (5′-CCGYCAATTYMTTTRAGTTT- 3′) (Caporaso et al., 2001).\n",
    "- First, make sure you install cutadapt following the instructions here: https://cutadapt.readthedocs.io/en/stable/installation.html\n",
    "- Second, you will use mkdir to create a separate directory for the trimmed reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir primer-trimmed-reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831adb0d",
   "metadata": {},
   "source": [
    "- Then, you will execute the following command to verify that the looping through the sample IDs will be performed correctly by cutadapt - if not pointing to the correct location, we would get a “No such file or directory”-."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in $(cat unique-sample-IDs.txt)\n",
    "do\n",
    "\n",
    "    echo \"On sample: ${sample}\"\n",
    "\n",
    "    echo \"    Forward read file location:\"\n",
    "    ls ${sample}_L001_R1_001.fastq.gz\n",
    "    \n",
    "    echo \"    Reverse read file location:\"\n",
    "    ls ${sample}_L001_R2_001.fastq.gz\n",
    "    \n",
    "    # just adding a blank line in between samples as they print out\n",
    "    echo \"\"\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cf03c3",
   "metadata": {},
   "source": [
    "If the unique-sample-IDs.txt file was created correctly, we should get a list of sample IDs with their corresponding filenames for the forward and reverse filenames. After this, you can run cutadapt to remove the primers from all the sequences (delete the comments after # before running):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in $(cat unique-sample-IDs.txt)\n",
    "do\n",
    "\n",
    "    echo \"On sample: ${sample}\"\n",
    "\n",
    "    cutadapt -g GTGYCAGCMGCCGCGGTAA \\ #this is the forward primer sequence \n",
    "                                       # to be found in the fwd read\n",
    "             -G CCGYCAATTYMTTTRAGTTT \\ #this is the reverse primer sequence \n",
    "                                        # to be found in the reverse read\n",
    "             -o primer-trimmed-reads/${sample}-trimmed-R1.fastq.gz \\ #this is the name that the \n",
    "                                                       # output forward trimmed reads will have\n",
    "             -p primer-trimmed-reads/${sample}-trimmed-R2.fastq.gz \\ #this is the name that the\n",
    "                                                        #output reverse trimmed reads will have\n",
    "             --discard-untrimmed \\ #untrimmed sequences will be discarded\n",
    "             ${sample}_L001_R1_001.fastq.gz \\\n",
    "             ${sample}_L001_R2_001.fastq.gz \\\n",
    "             >> cutadapt-primer-trimming-output.txt 2>&1\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7173b4",
   "metadata": {},
   "source": [
    "To confirm that the output is correct, take a look at the generated file with the less command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "less cutadapt-primer-trimming-output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13040e6",
   "metadata": {},
   "source": [
    "For this particular dataset, the Summary should read as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b220a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "=== Summary ===\n",
    "\n",
    "Total read pairs processed:             27,535\n",
    "  Read 1 with adapter:                  27,006 (98.1%)\n",
    "  Read 2 with adapter:                  27,265 (99.0%)\n",
    "Pairs written (passing filters):        26,742 (97.1%)\n",
    "\n",
    "Total basepairs processed:    16,576,070 bp\n",
    "  Read 1:     8,288,035 bp\n",
    "  Read 2:     8,288,035 bp\n",
    "Total written (filtered):     15,055,874 bp (90.8%)\n",
    "  Read 1:     7,541,306 bp\n",
    "  Read 2:     7,514,568 bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30ef8d",
   "metadata": {},
   "source": [
    "To exit the less output window, just press q. To identify the percentage of reads retained, we can select from the previous file only the lines that include \"Pairs\" with the grep command, and take a look at the first 3 lines of the file by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grep \"Pairs\" cutadapt-primer-trimming-output.txt | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478ea1f",
   "metadata": {},
   "source": [
    "To extract only the percentages, we can cut them out using the cut command and save them in a file called percent-reads-retained.tmp by running the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13706a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "grep \"Pairs\" cutadapt-primer-trimming-output.txt | cut -f 3 -d \"(\" | tr -d \")\" > \n",
    "percent-reads-retained.tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43594428",
   "metadata": {},
   "source": [
    "In this case, -f 3 extracts the third column, d specifices the delimiter as \"(\", and tr -d \")\" removes the trailing ). Now, we will fuse this file with the uniqie-sample-IDs.txt file with paste into a new file called percent-reads-retained-after-primer-removal.tsv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "paste unique-sample-IDs.txt percent-reads-retained.tmp\\\n",
    "> percent-reads-retained-after-primer-removal.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5712ba5",
   "metadata": {},
   "source": [
    "We will remove the intermediate file with rm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872bc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm percent-reads-retained.tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53831991",
   "metadata": {},
   "source": [
    "And finally, we will look at the table we created, that included only identifiers and the percentage of reads retained after primer removal using cat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat percent-reads-retained-after-primer-removal.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
